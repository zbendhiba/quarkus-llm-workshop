# The deployed model is using a self-signed certificate, so we need to trust it.
#quarkus.tls.trust-all=true


#quarkus.langchain4j.openai.log-requests=true
#quarkus.langchain4j.openai.log-responses=true


#quarkus.langchain4j.mistralai.base-url=https://mistral7b02-vllm-gpu-ch2023.apps.cluster-hj2qv.dynamic.redhatworkshops.io/v1/
#quarkus.langchain4j.openai.base-url=https://mistral7b02-vllm-gpu-llms.apps.cluster-kw5mq.sandbox1712.opentlc.com/v1/
#quarkus.langchain4j.openai.api-key=${NOMIC_KEY_API}
#quarkus.langchain4j.openai.embedding-model.inference-endpoint-url=https://api-atlas.nomic.ai/v1/embedding/text

#quarkus.langchain4j.openai.chat-model.model-name=/mnt/models/
#quarkus.langchain4j.openai.chat-model.enabled=true
#quarkus.langchain4j.openai.embedding-model.inference-endpoint-url=https://api-atlas.nomic.ai/v1/embedding/text

#quarkus.langchain4j.chat-model.provider=openai

#quarkus.langchain4j.infinispan.dimension=384

#quarkus.langchain4j.huggingface.log-requests=true
#quarkus.langchain4j.huggingface.log-responses=true



#quarkus.langchain4j.huggingface.chat-model.enabled=false
quarkus.langchain4j.infinispan.dimension=384


quarkus.langchain4j.ollama.chat-model.model-id=mistral
quarkus.langchain4j.ollama.timeout=60s

quarkus.langchain4j.ollama.base-url=http://localhost:11434/api
quarkus.langchain4j.embedding-model.provider=dev.langchain4j.model.embedding.AllMiniLmL6V2EmbeddingModel

#' needs to be set to one of the available options (ollama,dev.langchain4j.model.embedding.AllMiniLmL6V2EmbeddingModel).



quarkus.langchain4j.infinispan.dimension=4096
#quarkus.redis.devservices.image-name=redis/redis-stack:latest


